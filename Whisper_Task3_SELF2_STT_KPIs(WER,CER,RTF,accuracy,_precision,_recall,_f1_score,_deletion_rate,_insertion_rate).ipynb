{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install whisper\n",
        "!pip install jiwer\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x2xxgzuMt8N",
        "outputId": "850dbbdd-b87a-46f5-ed3a-29e3824aef4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: whisper in /usr/local/lib/python3.10/dist-packages (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import whisper\n",
        "import torch\n",
        "from jiwer import wer, cer, mer, compute_measures\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time\n"
      ],
      "metadata": {
        "id": "qrcDcQIEMt_6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2VjiSI0tNTik",
        "outputId": "c1936702-8963-4b52-a2ec-881132c539cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numba (from openai-whisper)\n",
            "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy (from openai-whisper)\n",
            "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper)\n",
            "  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting tqdm (from openai-whisper)\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting more-itertools (from openai-whisper)\n",
            "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting filelock (from triton>=2.0.0->openai-whisper)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
            "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy (from openai-whisper)\n",
            "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
            "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26.0 (from tiktoken->openai-whisper)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch->openai-whisper)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch->openai-whisper)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->openai-whisper)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch->openai-whisper)\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting sympy==1.13.1 (from torch->openai-whisper)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->openai-whisper)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper)\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=829b0eadaf3443e9370496fbaff58b4cf613bb9e73c96a1f0784914361bda729\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, more-itertools, MarkupSafe, llvmlite, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, jinja2, tiktoken, nvidia-cusolver-cu12, torch, openai-whisper\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.9.11\n",
            "    Uninstalling regex-2024.9.11:\n",
            "      Successfully uninstalled regex-2024.9.11\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 10.5.0\n",
            "    Uninstalling more-itertools-10.5.0:\n",
            "      Successfully uninstalled more-itertools-10.5.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.0\n",
            "    Uninstalling charset-normalizer-3.4.0:\n",
            "      Successfully uninstalled charset-normalizer-3.4.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.10.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2024.8.30 charset-normalizer-3.4.0 filelock-3.16.1 fsspec-2024.10.0 idna-3.10 jinja2-3.1.4 llvmlite-0.43.0 more-itertools-10.5.0 mpmath-1.3.0 networkx-3.4.2 numba-0.60.0 numpy-2.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-whisper-20240930 regex-2024.9.11 requests-2.32.3 sympy-1.13.1 tiktoken-0.8.0 torch-2.5.0 tqdm-4.66.5 triton-3.1.0 typing-extensions-4.12.2 urllib3-2.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "torch",
                  "torchgen",
                  "tqdm",
                  "whisper"
                ]
              },
              "id": "52bdae11619641b8ad7b74454ed45370"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06zmZ7gZMuCK",
        "outputId": "b19dddae-17b7-4874-8c28-895d6bc56462"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:21<00:00, 72.0MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(predicted_text, reference_text):\n",
        "    # Word Error Rate\n",
        "    wer_score = wer(reference_text, predicted_text)\n",
        "\n",
        "    # Character Error Rate\n",
        "    cer_score = cer(reference_text, predicted_text)\n",
        "\n",
        "    # Match Error Rate\n",
        "    mer_score = mer(reference_text, predicted_text)\n",
        "\n",
        "    # Additional metrics (deletion, insertion)\n",
        "    measures = compute_measures(reference_text, predicted_text)\n",
        "    deletion_rate = measures['deletions'] / measures['substitutions']\n",
        "    insertion_rate = measures['insertions'] / measures['substitutions']\n",
        "\n",
        "    # Return all metrics\n",
        "    return {\n",
        "        \"WER\": wer_score,\n",
        "        \"CER\": cer_score,\n",
        "        \"MER\": mer_score,\n",
        "        \"Deletion Rate\": deletion_rate,\n",
        "        \"Insertion Rate\": insertion_rate\n",
        "    }"
      ],
      "metadata": {
        "id": "Gs53lCgPMuEN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import whisper\n",
        "from jiwer import wer, cer, mer, compute_measures\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import time"
      ],
      "metadata": {
        "id": "gSYRqW4fRHFb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import whisper  # Ensure you have the whisper model imported\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the paths for audio recordings and transcripts\n",
        "recordings_folder = \"recordings\"\n",
        "transcripts_folder = \"transcribed\"\n",
        "metrics_results = []\n",
        "\n",
        "# Function to compute evaluation metrics\n",
        "def compute_metrics(predicted_text, reference_text):\n",
        "    # Word Error Rate\n",
        "    wer_score = wer(reference_text, predicted_text)\n",
        "\n",
        "    # Character Error Rate\n",
        "    cer_score = cer(reference_text, predicted_text)\n",
        "\n",
        "    # Match Error Rate\n",
        "    mer_score = mer(reference_text, predicted_text)\n",
        "\n",
        "    # Calculate true positives, false positives, and false negatives\n",
        "    reference_words = reference_text.split()\n",
        "    predicted_words = predicted_text.split()\n",
        "\n",
        "    tp = len(set(reference_words) & set(predicted_words))  # True Positives\n",
        "    fp = len(set(predicted_words) - set(reference_words))  # False Positives\n",
        "    fn = len(set(reference_words) - set(predicted_words))  # False Negatives\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = (tp) / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "    precision = (tp) / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = (tp) / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Additional metrics (deletion, insertion)\n",
        "    measures = compute_measures(reference_text, predicted_text)\n",
        "    deletion_rate = measures['deletions'] / measures['substitutions'] if measures['substitutions'] > 0 else 0\n",
        "    insertion_rate = measures['insertions'] / measures['substitutions'] if measures['substitutions'] > 0 else 0\n",
        "\n",
        "    # Return all metrics\n",
        "    return {\n",
        "        \"WER\": wer_score,\n",
        "        \"CER\": cer_score,\n",
        "        \"MER\": mer_score,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"Deletion Rate\": deletion_rate,\n",
        "        \"Insertion Rate\": insertion_rate\n",
        "    }\n",
        "\n",
        "# Loop through each WAV file\n",
        "for filename in os.listdir(recordings_folder):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        wav_path = os.path.join(recordings_folder, filename)\n",
        "\n",
        "        try:\n",
        "            # Load corresponding text transcript\n",
        "            transcript_path = os.path.join(transcripts_folder, filename.replace(\".wav\", \".txt\"))  # Change to .txt\n",
        "            with open(transcript_path, \"r\") as f:\n",
        "                reference_text = f.read().strip()  # Read the text file content\n",
        "\n",
        "            # Start timer for Real-Time Factor\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Transcribe the audio file\n",
        "            result = model.transcribe(wav_path)\n",
        "            predicted_text = result[\"text\"]\n",
        "\n",
        "            # Calculate Real-Time Factor (RTF)\n",
        "            duration = whisper.audio.load_audio(wav_path).shape[-1] / whisper.audio.SAMPLE_RATE\n",
        "            rtf = (time.time() - start_time) / duration\n",
        "\n",
        "            # Compute metrics\n",
        "            metrics = compute_metrics(predicted_text, reference_text)\n",
        "            metrics[\"RTF\"] = rtf  # Add Real-Time Factor\n",
        "            metrics[\"Filename\"] = filename\n",
        "\n",
        "            metrics_results.append(metrics)\n",
        "\n",
        "        except (FileNotFoundError, RuntimeError) as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "# Calculate averages\n",
        "if metrics_results:  # Ensure there are results to average\n",
        "    average_metrics = {\n",
        "        \"WER\": sum(result[\"WER\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"CER\": sum(result[\"CER\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"MER\": sum(result[\"MER\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"Accuracy\": sum(result[\"Accuracy\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"Precision\": sum(result[\"Precision\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"Recall\": sum(result[\"Recall\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"F1 Score\": sum(result[\"F1 Score\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"Deletion Rate\": sum(result[\"Deletion Rate\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"Insertion Rate\": sum(result[\"Insertion Rate\"] for result in metrics_results) / len(metrics_results),\n",
        "        \"RTF\": sum(result[\"RTF\"] for result in metrics_results) / len(metrics_results),\n",
        "    }\n",
        "\n",
        "    # Print out average results\n",
        "    print(\"Average Metrics:\")\n",
        "    print(f\"  WER: {average_metrics['WER']:.2f}\")\n",
        "    print(f\"  CER: {average_metrics['CER']:.2f}\")\n",
        "    print(f\"  MER: {average_metrics['MER']:.2f}\")\n",
        "    print(f\"  Accuracy: {average_metrics['Accuracy']:.2f}\")\n",
        "    print(f\"  Precision: {average_metrics['Precision']:.2f}\")\n",
        "    print(f\"  Recall: {average_metrics['Recall']:.2f}\")\n",
        "    print(f\"  F1 Score: {average_metrics['F1 Score']:.2f}\")\n",
        "    print(f\"  Deletion Rate: {average_metrics['Deletion Rate']:.2f}\")\n",
        "    print(f\"  Insertion Rate: {average_metrics['Insertion Rate']:.2f}\")\n",
        "    print(f\"  RTF: {average_metrics['RTF']:.2f}\")\n",
        "else:\n",
        "    print(\"No valid recordings were processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfFUpwHCMuGF",
        "outputId": "da046012-9ab2-4419-fe64-92962bdd2430"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metrics:\n",
            "  WER: 0.27\n",
            "  CER: 0.16\n",
            "  MER: 0.27\n",
            "  Accuracy: 0.58\n",
            "  Precision: 0.75\n",
            "  Recall: 0.71\n",
            "  F1 Score: 0.73\n",
            "  Deletion Rate: 0.15\n",
            "  Insertion Rate: 0.08\n",
            "  RTF: 0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"medium\")  # You can choose a different model size like 'tiny', 'small', 'medium', or 'large'\n",
        "\n",
        "# Define the path to your audio recordings\n",
        "recordings_folder = \"recordings\"\n",
        "transcripts_folder = \"transcripts\"\n",
        "\n",
        "# Create the transcripts folder if it doesn't exist\n",
        "os.makedirs(transcripts_folder, exist_ok=True)\n",
        "\n",
        "# Loop through each WAV file in the recordings folder\n",
        "for filename in os.listdir(recordings_folder):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        wav_path = os.path.join(recordings_folder, filename)\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        result = model.transcribe(wav_path)\n",
        "        predicted_text = result[\"text\"]\n",
        "\n",
        "        # Save the transcript to a text file\n",
        "        transcript_path = os.path.join(transcripts_folder, filename.replace(\".wav\", \".txt\"))\n",
        "        with open(transcript_path, \"w\") as f:\n",
        "            f.write(predicted_text)\n",
        "\n",
        "        print(f\"Transcribed {filename} and saved to {transcript_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK8dmotPrICO",
        "outputId": "79536599-7e5a-40fc-cb3c-79a93341eefc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed S10.wav and saved to transcripts/S10.txt\n",
            "Transcribed S21.wav and saved to transcripts/S21.txt\n",
            "Transcribed S3.wav and saved to transcripts/S3.txt\n",
            "Transcribed S6.wav and saved to transcripts/S6.txt\n",
            "Transcribed S13.wav and saved to transcripts/S13.txt\n",
            "Transcribed S20.wav and saved to transcripts/S20.txt\n",
            "Transcribed S4.wav and saved to transcripts/S4.txt\n",
            "Transcribed S17.wav and saved to transcripts/S17.txt\n",
            "Transcribed S16.wav and saved to transcripts/S16.txt\n",
            "Transcribed S1.wav and saved to transcripts/S1.txt\n",
            "Transcribed S8.wav and saved to transcripts/S8.txt\n",
            "Transcribed S15.wav and saved to transcripts/S15.txt\n",
            "Transcribed S9.wav and saved to transcripts/S9.txt\n",
            "Transcribed S2.wav and saved to transcripts/S2.txt\n",
            "Transcribed S14.wav and saved to transcripts/S14.txt\n",
            "Transcribed S12.wav and saved to transcripts/S12.txt\n",
            "Transcribed S5.wav and saved to transcripts/S5.txt\n",
            "Transcribed S11.wav and saved to transcripts/S11.txt\n",
            "Transcribed S18.wav and saved to transcripts/S18.txt\n",
            "Transcribed S19.wav and saved to transcripts/S19.txt\n",
            "Transcribed S7.wav and saved to transcripts/S7.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"medium\")  # You can choose a different model size like 'tiny', 'small', 'medium', or 'large'\n",
        "\n",
        "# Define the path to your audio recordings\n",
        "recordings_folder = \"recordings\"\n",
        "transcripts_folder = \"transcripts\"\n",
        "\n",
        "# Create the transcripts folder if it doesn't exist\n",
        "os.makedirs(transcripts_folder, exist_ok=True)\n",
        "\n",
        "# Loop through each WAV file in the recordings folder\n",
        "for filename in os.listdir(recordings_folder):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        wav_path = os.path.join(recordings_folder, filename)\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        result = model.transcribe(wav_path)\n",
        "        predicted_text = result[\"text\"]\n",
        "\n",
        "        # Save the transcript to a text file\n",
        "        transcript_path = os.path.join(transcripts_folder, filename.replace(\".wav\", \".txt\"))\n",
        "        with open(transcript_path, \"w\") as f:\n",
        "            f.write(predicted_text)\n",
        "\n",
        "        # Print the transcript to the output\n",
        "        print(f\"Transcribed {filename}:\")\n",
        "        print(predicted_text)\n",
        "        print(\"\\n\" + \"-\" * 40 + \"\\n\")  # Separator for readability\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIZROieOs9Xf",
        "outputId": "669d48d9-90be-42ac-d504-e0e903cc33c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed S10.wav:\n",
            " Hi, have you been managing your asthma lately? Hi doctor, it's been a bit challenging. I have had a couple of attacks, especially when I am outside in the cold. I see cold air can be trigger for many people. Have you been using your inhaler regularly? I use it when I feel busy, but I am not consistent about using it daily. It's crucial to have a preventive strategy in place. Let's review your asthma action plan and see if we need to adjust your medication. That sounds good. I want to be more proactive about it.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S21.wav:\n",
            " Hello, how is your exercise and routine being going? Hi doctor, I've been trying to stick to a routine but it's been hard to stay motivated. Motivation can be a challenge. What type of activities do you enjoy? I like biking but I don't always have time. Have you considered shorter, more frequent workouts? Even 15-20 minutes a day can make a difference. That sounds doable. I'll give it a try.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S3.wav:\n",
            " What symptoms have you been experiencing lately? Mostly sneezing and itchy eyes. It's been worse in the mornings when I wake up. Do you experience any congestion or difficulty breathing? A bit congested eye, but I don't feel short of breath. That's a good sign. Have you noticed any specific triggers like being outdoors or certain activities? Yes, being outside makes it worse, especially when the poland count is high. It sounds like typical seasonal allergies. Let's discuss some treatment options like antihistamines or nasal sprays. I have tried some over-the-counter antihistamines, but they don't seem to work as well for me. We might need to explore stronger options or even consider allergy testing if the symptoms persist. Would you like to discuss lifestyle changes that could help manage your symptoms as well? Yes, that would be very helpful. I want to minimize my symptoms as much as possible, doctor. Great! We can work together on a comprehensive plan.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S6.wav:\n",
            " It's great to see you for your annual checkup. How have you been feeling? Hi doctor, I have been feeling pretty good, but I am little concerned about my cholesterol levels. I see. We did some blood work last time and your cholesterol was slightly elevated. Have you made any changes to your diet since then? I have been trying to eat healthier like incorporating more fruits and vegetables, but I still find myself eating out a lot. Eating out can be tricky, especially with portion sizes and hidden fats. Have you considered meal prepping or keeping healthier snacks handy? I have thought about it, but it's hard to find the time actually. Okay, I understand. Even small changes can help, like choosing grilled options or salads. Let's also talk about physical activity. Are you able to exercise regularly? I do go for walks a few times a week, but I did like to do more. That's a great start. Let's set some specific goals for your exercise and discuss ways to manage your cholesterol effectively.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S13.wav:\n",
            " Hello, I wanted to follow up on your sleep issues. How have you been sleeping? Hi doctor, not yet. I am still waking up several times a night. I see. Have you tried any of the techniques we discussed like emitting screen time before bed? I have tried but it's hard to stick to it. I often end up scrolling through my phone. That's understandable. Let's talk about establishing a bedtime routine that works for you and consider whether we need to adjust your sleep aids. Yes, I did like to explore other options.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S20.wav:\n",
            " Hi, I wanted to check in on your mental health since our last appointment. How have you been feeling? Hi doctor, I've been feeling a bit down lately, more than usual. I'm sorry to hear that. Have there been any specific triggers for this feeling? I think the stress from the work and some family issues have been weighing on me. That's understandable. Let's explore some coping strategies and consider whether therapy or medication might be beneficial. I'll be open to that. I just want to feel better.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S4.wav:\n",
            " Hi there, it's been a while since our last appointment. How have you been feeling emotionally? Hi Doctor, honestly I've been feeling a bit overwhelmed lately. I'm sorry to hear that. What do you think has been contributing to those feelings? Work has been really stressful and I've been trouble sleeping. Lack of sleep can definitely impact your mood. How long has this been going on? For about a month now, I find myself feeling anxious during the day and then exhausted by the evening. That sounds tough. Have you tried any strategies to manage your stress or improve your sleep? I've tried meditation and limiting my screen time, but it hasn't made a significant difference it seems. It's good that you're trying different approaches. Would you be open to discussing some cognitive behavioural strategies or possibly adjusting your treatment plan? Yes, I did really appreciate that Doctor.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S17.wav:\n",
            " Hi there, it's allergy season again. How have you been coping with your symptoms? Hi doctor, my allergies have been really bad this year. I'm sneezing constantly. I'm sorry to hear that. Have you been taking your allergy medications regularly? I've been taking it but it doesn't seem to help much. Let's review what you're using. Sometimes we might need to adjust the dosage or switch to a different medication. That makes sense. I'd love to find something that works better.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S16.wav:\n",
            " Hello, how have you been managing your blood pressure since we last spoke? Hi doctor, I've been trying to monitor it at home but I still get nervous when I come in for checkup. That's understandable. Have you been following the lifestyle changes we discussed? I've cut back on salt and started exercising more but I'm still struggling with my numbers. Let's look at your reading. We might need to adjust your medication or explore additional lifestyle modifications. I'd appreciate that. I really want to get my blood pressure under control.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S1.wav:\n",
            " What brings you in today? Good morning doctor, I have been experiencing some lower back pain for the past couple of weeks. I am sorry to hear that. Can you describe the pain? Is it sharp, dull or more of an ache? It's more of a dull ache but it gets worse when I sit for long periods or bend over. Understood. On a scale of 1 to 10, how would you rate the pain when it's at its worst? I did say it's about a 7 when it's bad. That sounds uncomfortable. Have you tried anything to relieve the pain like ice, rest or over the counter medication? I have tried resting and taking some ibuprofen which helps a bit but it always comes back when I move around. I see. Have you had any previous back issues or did this start suddenly? I had some minor issues a few years ago but nothing like this. Got it. Let's do a physical examination to assess your range of motion and check for any tenderness. After that we can discuss the potential treatments.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S8.wav:\n",
            " Hi, I see you are here about the rash on your arm. Can you describe it when it started? Hi doctor, it began about a week ago. At first it was just a small touch but it spread and itches quite a bit. That sounds uncomfortable. Have you tried anything to relieve the itching? I have been using some hydrocovarticin cream I had at home but it doesn't seem to help very much. It's good you tried that. Have you noticed any new products you have used or changes in your environment that might have triggered this? I did some using a new boundary detergent a couple of weeks ago but I didn't think it would cause a rash. It could be an allergic reaction. Let's take a closer look at the rash and discuss the treatment option. If it doesn't improve we might consider allergy testing.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S15.wav:\n",
            " Hi, I wanted to check in regarding the medication changes we made last time. How have you been feeling? Hi doctor, I think the new medication is working better, but I have noticed some side effects. What kind of side effects are you experiencing? I have been feeling more tired and a bit dizzy, especially in the mornings. Those can be common within this medication. Let's discuss your dosage and timing to see if we can minimize those effects. That would be great. I want to feel more energetic.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S9.wav:\n",
            " Hello, it's great to see you back after your boot with the flu. How are you feeling now? Hi doctor, I'm feeling much better, thanks. The fever is gone but I still have some lingering fatigue. That's a positive sign. Fatigue can be stick around even after the other symptoms have improved. Are you staying hydrated and getting plenty of rest? Yes, I've been trying to drink lots of fluids and rest as much as possible. That's important. It might take a bit more time for his energy levels to return fully. If you still feel fatigue in a week, we can do some blood work and ensure everything is ok. That makes sense, I'll keep an eye on it.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S2.wav:\n",
            " Hi, it's good to see you again. How have you been feeling since starting the new blood pressure medication? Hi doctor, I've been feeling okay but I think the medication is making me a bit tired. That's not uncommon. Have you been monitoring your blood pressure at home? Yes I have. My readings mostly have been in a normal range but I do feel a bit light headed sometimes. That's important to note. Light headedness can sometimes happen when starting a new medication. Have you noticed any other side effects? No, no. Just the tiredness. I haven't experienced any swelling or headaches. That's good to hear. Let's take a look at your blood pressure today and evaluate if we need to adjust your medication. Sometimes the body takes time to adjust. Okay, I hope it gets better soon. I'm confident it will. Let's also discuss lifestyle changes that can support your treatment like diet and exercise.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S14.wav:\n",
            " Hi, it's good to see you again. Have you been managing your diabetes? Hi doctor, I am trying to keep my blood sugar stable but I struggle with cravings. Cravings can be tough to deal with. Are you keeping track on your meals? I have been but I often give in to sugary snacks. Let's discuss some healthy alternatives that can satisfy those cravings without impacting your blood sugar too much. You can also explore meal timing and portions. That will help a lot. I want to stay on track.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S12.wav:\n",
            " Hi, I see you are here about your headaches. Can you tell me how often they occur? Hi doctor, they have been happening about 3 times a week and they last for a few hours. That sounds difficult to manage. Are there any specific triggers you have noticed? Bright lights and shades seem to make them worse. I also feel nauseous sometimes. Nausea can be a common symptom with headaches. Let's discuss some treatment options and strategies for prevention. That will be helpful. I just want to get back to normal.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S5.wav:\n",
            " Good afternoon. Let's discuss how your diabetes management has been going on. Good afternoon, Doctor. I've been trying to follow the meal plan, but I occasionally slip up. It's understandable. Can you tell me what kinds of foods have you been challenging? Doctor, I have a sweet tooth, so I struggle with desserts and sugary drinks. That's a common challenge. Have you been checking your blood sugar regularly? Yes, I check it every morning and it has been fluctuating a bit. Okay, let's take a look at your recent readings and see how they correlate with your diet. We can also explore some healthier dessert options. That sounds good. I need some alternatives that satisfy my cravings. Absolutely. Making small changes can make a big difference.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S11.wav:\n",
            " Hello, how has your weight loss journey been since our last visit? Hi doctor, I have lost a few pounds but I feel stuck now. That's a great start. The tick can be frustrating. What changes have you made to your diet and exercise? I have been tracking my meals and trying to go for walks but it feels like I am not making progress. It might help to adjust your calorie intake or increase your activity level. Let's look at your food diary and see where we can make improvements. I did appreciate that. I want to keep moving forward.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S18.wav:\n",
            " Hello, I see you have gained a bit of weight since our last visit. Can you tell me about any changes in your routine? Hi doctor, I have been more sedentary with work and I have also been eating out more. Those can definitely contribute. Have you considered meal prepping or finding quick healthy recipes? I haven't really thought about it. I usually grab whatever is convenient. Let's talk about planning some meals and also incorporating more physical activity into your day. That sounds like a good idea. I want to get back on track.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S19.wav:\n",
            " Hi, how is your recovery been since the surgery? Hi doctor, it's been going well but I still have some pain in the incision light. Pain can be normal but it's important to monitor it. Have you been following other post-OP care instructions? Yes, I've been keeping it clean and dry but I'm worried if the pain is a sign of something wrong. Let's take a look. If it's consistent with the healing process, we can discuss pain management options. I'd feel better knowing it's normal.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Transcribed S7.wav:\n",
            " Hi there, how have you been since we last discussed your anxiety? Hi doctor, I've been doing a little better but I still have few days when it feels overwhelming. It's good to hear there's some improvement. Can you tell me more about those overwhelming days? They usually happen when I have a lot on my plate like work deadlines or family commitments. I feel like I can't cope up. That's understandable. Have you been using the coping strategies we discussed like deep breathing or mindfulness? Doctor, I've tried deep breathing but I forget to do it when I'm feeling anxious actually. Okay, it can be tough to remember in the moment. Maybe setting reminders on your phone could help. Have you noticed any triggers that increase your anxiety? Yes, crowded places and stressful conversations really get me. Let's work on some techniques for those situations. We can also explore whether adjusting your medication might provide additional support. I'm open to that doctor. I want to manage it better.\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Implement Noise Reduction on Audio Files"
      ],
      "metadata": {
        "id": "aGAOJRXL5pym"
      }
    }
  ]
}